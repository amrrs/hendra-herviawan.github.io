<!DOCTYPE html>
<html lang="en-us">
  <head>
		
		<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
		new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
		j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
		'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
		})(window,document,'script','dataLayer','GTM-5CXDD64');</script>
		
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.30.2" />


<title>Univariate logistic regression with Tensorflow - M Hendra Herviawan~Blog</title>
<meta property="og:title" content="Univariate logistic regression with Tensorflow - M Hendra Herviawan~Blog">



  








<link href='//cdn.bootcss.com/highlight.js/9.11.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="kaggle.com/hendraherviawan/kernels">Kaggle</a></li>
    
    <li><a href="/tutorial/">Tutorial</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    

    <h1 class="article-title">Univariate logistic regression with Tensorflow</h1>

    

    <div class="article-content">
      

<h3 id="m-hendra-herviawan">M Hendra Herviawan</h3>

<h2 id="project-overview">Project Overview</h2>

<p>Logistic regression adalah model statistical untuk menganalisa data dimana terdapat satu atau lebih independent variable dan mengeluarkan Output dichotomi variable (hanya terdapat dua kemungkinan). Sebuah Neuron pada Neural network merupakan <em>Logistic regression</em> yang menerima satu atau lebih input dan mengeluarkan probabilitas antara 0 dan 1.</p>

<pre><code class="language-python">import os  
os.environ[&quot;CUDA_DEVICE_ORDER&quot;] = &quot;PCI_BUS_ID&quot;   # see issue #152  
os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;&quot;  
</code></pre>

<pre><code class="language-python">import numpy as np
import pandas as pd

from sklearn import datasets, metrics, preprocessing
from sklearn.utils import shuffle

training_epochs = 20
batch_size = 100
</code></pre>

<h2 id="load-dataset">Load Dataset</h2>

<pre><code class="language-python">#Load the dataset
df = pd.read_csv(&quot;../../_dataset/CHD.csv&quot;, header=0)
#Describe the input data
print (df.describe())
</code></pre>

<pre><code>              age        chd
count  100.000000  100.00000
mean    44.380000    0.43000
std     11.721327    0.49757
min     20.000000    0.00000
25%     34.750000    0.00000
50%     44.000000    0.00000
75%     55.000000    1.00000
max     69.000000    1.00000
</code></pre>

<h3 id="normalizing-and-shuffle-the-data">Normalizing and Shuffle the data</h3>

<pre><code class="language-python">#Normalisasi input data
a = preprocessing.StandardScaler()
X =a.fit_transform(df['age'].values.reshape(-1, 1).astype(float))

#Shuffle
x_sf,y_sf = shuffle(X, df['chd'])
#x_sf,y_sf = X, df['chd']
</code></pre>

<pre><code class="language-python">x_sf[1:5]
</code></pre>

<pre><code>array([[ 0.05316151],
       [ 0.91060526],
       [ 1.42507151],
       [ 0.73911651]])
</code></pre>

<pre><code class="language-python">y_sf[1:5]
</code></pre>

<pre><code>52    0
74    1
92    1
70    1
Name: chd, dtype: int64
</code></pre>

<h2 id="1-tensorflow">1. Tensorflow</h2>

<pre><code class="language-python">import tensorflow as tf
</code></pre>

<pre><code class="language-python">sess = tf.Session()
# tf Graph Input
x = tf.placeholder(&quot;float&quot;, [None, 1]) 
y = tf.placeholder(&quot;float&quot;, [None, 1]) 

# Create model
# Set model weights
W = tf.Variable(tf.zeros([1, 1]))
b = tf.Variable(tf.zeros([1])) #Two Label
</code></pre>

<pre><code class="language-python">learning_rate = 0.2

# Construct model
pred = tf.matmul(x, W) + b
activation = tf.nn.sigmoid(pred) 

# Minimize error using cross entropy
cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(activation), axis=1)) # Cross entropy
#optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost) # Gradient Descent
optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)
</code></pre>

<pre><code class="language-python"># Parameters

display_step = 5

# Initializing the variables
init = tf.global_variables_initializer()

# Launch the graph
with tf.Session() as sess:
    sess.run(init)
    
    
    #Iterate through all the epochs
    for epoch in range(training_epochs):
        avg_cost = 0.
        total_batch = int(90/batch_size) #?
        # Loop over all batches

        #for i in range(total_batch):
        # Transform the array into a one hot format

        #temp=tf.one_hot(indices = y_sf.values, depth=2, on_value = 1, off_value = 0, axis = -1 , name = &quot;a&quot;)  
        #batch_xs, batch_ys = ((np.transpose([df['age']])-44.38)/11.721327)[:90], temp
        temp = (y_sf.values.astype(np.float))[:90]
        batch_xs, batch_ys = x_sf[:90], temp.reshape(temp.shape[0], 1)

        # Fit training using batch data
        sess.run(optimizer, feed_dict={x: batch_xs.astype(float), y: batch_ys})

        # Compute average loss, suming the corrent cost divided by the batch total number
        avg_cost += sess.run(cost, feed_dict={x: batch_xs.astype(float), y: batch_ys})#/total_batch
        # Display logs per epoch step

        if (epoch % display_step == 0) or (epoch+1 == training_epochs):
            print (&quot;Epoch:&quot;, '%05d' % (epoch+1), &quot;cost=&quot;, &quot;{:.8f}&quot;.format(avg_cost))
            print (b.eval())
            print (W.eval())
            print ()
    
    test_X = x_sf[90:100] 
    test_Y = y_sf[90:100].values.reshape(y_sf[90:100].shape[0],1)
    
    testing_cost = sess.run(
        tf.reduce_sum(tf.pow(pred - y, 2)) / (2 * test_X.shape[0]),
        feed_dict={x: test_X, y: test_Y})  # same function as cost above
    print(&quot;Testing cost=&quot;, testing_cost)
    #print(&quot;Absolute mean square loss difference:&quot;, abs(
    #    training_cost - testing_cost))
</code></pre>

<pre><code>Epoch: 00001 cost= 0.29435056
[ 0.04672056]
[[ 0.02747042]]

Epoch: 00006 cost= 0.23121341
[ 0.29183486]
[[ 0.1639497]]

Epoch: 00011 cost= 0.17904273
[ 0.55099446]
[[ 0.29210919]]

Epoch: 00016 cost= 0.13797809
[ 0.81854653]
[[ 0.40486109]]

Epoch: 00020 cost= 0.11200829
[ 1.03623283]
[[ 0.48145503]]

Testing cost= 0.169161
</code></pre>

<h2 id="2-keras">2. Keras</h2>

<pre><code class="language-python">from keras.models import Sequential
from keras.layers import Dense
</code></pre>

<pre><code>Using TensorFlow backend.
</code></pre>

<p>Untuk membuat model di Keras yang pertama dilakukan adalah memanggil fungsi <code>python Sequential()</code> sebagai simbol di mulainya <em>grapht</em>. Karena sebuah Neuron adalah penjabaran dari <em>logistic regression</em> maka untuk mengimplementasikan cukup dengan membuat satu neuron.</p>

<pre><code class="language-python">#Define the model as a logistic regression with
model = Sequential()
model.add(Dense(1, activation='sigmoid', input_dim=1)) #sigmoid or softmax
model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()
</code></pre>

<pre><code>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_6 (Dense)              (None, 1)                 2         
=================================================================
Total params: 2
Trainable params: 2
Non-trainable params: 0
_________________________________________________________________
</code></pre>

<pre><code class="language-python"># Fit the model with the first 90 elements, and spliting 70%/30% of them for training/validation sets
model.fit(x_sf[:90], y_sf[:90], epochs=training_epochs, validation_split=0.3, shuffle=False,verbose=1 )
</code></pre>

<pre><code>Train on 62 samples, validate on 28 samples
Epoch 1/20
62/62 [==============================] - 0s 2ms/step - loss: 0.8527 - acc: 0.3065 - val_loss: 0.8776 - val_acc: 0.2857
Epoch 2/20
62/62 [==============================] - 0s 117us/step - loss: 0.8509 - acc: 0.3065 - val_loss: 0.8758 - val_acc: 0.2857
Epoch 3/20
62/62 [==============================] - 0s 128us/step - loss: 0.8496 - acc: 0.3065 - val_loss: 0.8744 - val_acc: 0.2857
Epoch 4/20
62/62 [==============================] - 0s 174us/step - loss: 0.8485 - acc: 0.3065 - val_loss: 0.8731 - val_acc: 0.2857
Epoch 5/20
62/62 [==============================] - 0s 164us/step - loss: 0.8475 - acc: 0.3065 - val_loss: 0.8719 - val_acc: 0.2857
Epoch 6/20
62/62 [==============================] - 0s 140us/step - loss: 0.8466 - acc: 0.3065 - val_loss: 0.8708 - val_acc: 0.2500
Epoch 7/20
62/62 [==============================] - 0s 182us/step - loss: 0.8457 - acc: 0.3226 - val_loss: 0.8697 - val_acc: 0.2500
Epoch 8/20
62/62 [==============================] - 0s 182us/step - loss: 0.8449 - acc: 0.3226 - val_loss: 0.8687 - val_acc: 0.2500
Epoch 9/20
62/62 [==============================] - 0s 176us/step - loss: 0.8441 - acc: 0.3226 - val_loss: 0.8677 - val_acc: 0.2500
Epoch 10/20
62/62 [==============================] - 0s 167us/step - loss: 0.8433 - acc: 0.3226 - val_loss: 0.8667 - val_acc: 0.2500
Epoch 11/20
62/62 [==============================] - 0s 188us/step - loss: 0.8425 - acc: 0.3226 - val_loss: 0.8657 - val_acc: 0.2500
Epoch 12/20
62/62 [==============================] - 0s 188us/step - loss: 0.8418 - acc: 0.3226 - val_loss: 0.8647 - val_acc: 0.2500
Epoch 13/20
62/62 [==============================] - 0s 171us/step - loss: 0.8410 - acc: 0.3226 - val_loss: 0.8638 - val_acc: 0.2500
Epoch 14/20
62/62 [==============================] - 0s 145us/step - loss: 0.8403 - acc: 0.3226 - val_loss: 0.8628 - val_acc: 0.2500
Epoch 15/20
62/62 [==============================] - 0s 200us/step - loss: 0.8395 - acc: 0.3226 - val_loss: 0.8619 - val_acc: 0.2500
Epoch 16/20
62/62 [==============================] - 0s 179us/step - loss: 0.8388 - acc: 0.3226 - val_loss: 0.8610 - val_acc: 0.2500
Epoch 17/20
62/62 [==============================] - 0s 162us/step - loss: 0.8381 - acc: 0.3226 - val_loss: 0.8600 - val_acc: 0.2500
Epoch 18/20
62/62 [==============================] - 0s 153us/step - loss: 0.8373 - acc: 0.3226 - val_loss: 0.8591 - val_acc: 0.2500
Epoch 19/20
62/62 [==============================] - 0s 120us/step - loss: 0.8366 - acc: 0.3226 - val_loss: 0.8582 - val_acc: 0.2500
Epoch 20/20
62/62 [==============================] - 0s 170us/step - loss: 0.8359 - acc: 0.3226 - val_loss: 0.8573 - val_acc: 0.2500





&lt;keras.callbacks.History at 0x7f0b8830eeb8&gt;
</code></pre>

<pre><code class="language-python">#Evaluate the model with the last 10 elements
scores = model.evaluate(x_sf[90:], sfsdf, verbose=2)
print (model.metrics_names)
print (scores)

</code></pre>

<pre><code>['loss', 'acc']
[0.95378953218460083, 0.0]
</code></pre>

<pre><code class="language-python">
</code></pre>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdn.bootcss.com/highlight.js/9.11.0/highlight.min.js"></script>



<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/r.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/yaml.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/python.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/julia.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    

    
  </body>
</html>

